{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import tqdm\n",
    "import time\n",
    "import pdb\n",
    "import argparse\n",
    "import sys\n",
    "from shapes_loader import *\n",
    "from base_model import *\n",
    "import tf_homo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_leap_model = SuperPointNet().cuda()\n",
    "magic_leap_model.load_state_dict(torch.load('superpoint_v1.pth'))\n",
    "criterion = nn.Softmax(dim=1) #reduction='elementwise_sum')\n",
    "\n",
    "clr_imgs = Image.open('../hpatches-dataset/img/images.png').resize((2400,300),Image.ANTIALIAS)\n",
    "img1 = np.array(clr_imgs)\n",
    "img1 = img1[:300,:400]\n",
    "img1 = Image.fromarray(img1).convert('L')\n",
    "img1 = np.array(img1)\n",
    "\n",
    "img2 = np.array(clr_imgs)\n",
    "img2 = img2[:300,400:800]\n",
    "img2 = Image.fromarray(img2).convert('L')\n",
    "img2 = np.array(img2)\n",
    "\n",
    "#plt.imshow(Image.fromarray(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 65, 37, 50])\n",
      "torch.Size([1, 256, 37, 50])\n"
     ]
    }
   ],
   "source": [
    "probs_1, desc_1 = magic_leap_model(torch.from_numpy(img1).unsqueeze(0).unsqueeze(1).float().cuda())\n",
    "probs_2, desc_2 = magic_leap_model(torch.from_numpy(img2).unsqueeze(0).unsqueeze(1).float().cuda())\n",
    "print(probs_2.shape)\n",
    "print(desc_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65, 37, 50])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show matching results ...\n",
    "threshold = 0.4\n",
    "fig=plt.figure()\n",
    "plt.imshow()\n",
    "ipt_sm_1 = criterion(probs_1)\n",
    "ipt_sm_1 = ipt_sm_1[:,:-1,:,:]\n",
    "#find the max entry and confidence\n",
    "idx_conf_1, idx_locs_1 = ipt_sm_1.max(dim=1)\n",
    "idx_mask_1 = idx_conf_1 > threshold\n",
    "px = []\n",
    "py = []\n",
    "for x in range(prob.shape[2]):\n",
    "    for y in range(prob.shape[3]):\n",
    "        if idx_mask_1[0,x,y] == 1:\n",
    "            #location in the image\n",
    "            x_ = x*8 +(idx_locs_1[0,x,y]/8)\n",
    "            y_ = y*8 + (idx_locs_1[0,x,y]%8)\n",
    "            px.append(x_.item())\n",
    "            py.append(y_.item())\n",
    "plt.plot(py,px,'xy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
