{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "import os.path\n",
    "import pdb\n",
    "import argparse\n",
    "import sys\n",
    "from shapes_loader import *\n",
    "from base_model import *\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample homographies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warp image give\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape:  torch.Size([2, 300, 400])\n",
      "ML model output shape:  torch.Size([2, 65, 37, 50])\n",
      "ML model output shape:  torch.Size([2, 256, 37, 50])\n"
     ]
    }
   ],
   "source": [
    "# parameter \n",
    "threshold = 0.05\n",
    "\n",
    "# load in model\n",
    "magic_leap_model = SuperPointNet().to(DEVICE)\n",
    "model = torch.load('./Fri Nov  9 15:54:21 2018/e_405_a_10.9042.model').to(DEVICE)\n",
    "magic_leap_model.load_state_dict(torch.load('superpoint_v1.pth'))\n",
    "\n",
    "\n",
    "# load in images\n",
    "img_dir = '../test_coco/'\n",
    "imgsList = os.listdir(img_dir)\n",
    "clr_imgs = [Image.open(img_dir+img).resize((400,300),Image.ANTIALIAS) for img in imgsList]\n",
    "clr_imgs = clr_imgs[0]\n",
    "imgs = torch.tensor(np.asarray([np.array(Image.open(img_dir+img).resize((400,300),Image.ANTIALIAS).convert('1')) for img in imgsList], dtype='float')).to(DEVICE)  \n",
    "imgs = imgs[0:2]\n",
    "\n",
    "print('original image shape: ', imgs.shape)\n",
    "h,w = imgs[0].shape\n",
    "\n",
    "#ipt_1, desc_1 = model(imgs.float().unsqueeze(1).to(DEVICE))\n",
    "ipt_2, desc_2 = magic_leap_model(imgs.float().unsqueeze(1).to(DEVICE))\n",
    "\n",
    "#ipt bnum x 65 x hc x wc\n",
    "bnum, dims, hc, wc = ipt_2.shape\n",
    "print('ML model output shape: ', ipt_2.shape)\n",
    "print('ML model output shape: ', desc_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 65, 37, 50])\n",
      "torch.Size([2, 300, 400])\n"
     ]
    }
   ],
   "source": [
    "# homography adaptation\n",
    "counts = torch.ones(ipt_2.shape)\n",
    "\n",
    "print(ipt_2.shape)\n",
    "probs = ipt_2.unsqueeze(-1)\n",
    "counts = counts.unsqueeze(-1)\n",
    "images = imgs.unsqueeze(-1)\n",
    "shape = images.shape[:-1]\n",
    "print(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try tensorflow homography\n",
    "shape = tf.shape(images)[1:3]\n",
    "homography = sample_homography_tf(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts2 after perspective...: tensor([[0.0694, 0.1026],\n",
      "        [0.0694, 0.8974],\n",
      "        [0.8904, 0.9526],\n",
      "        [0.8904, 0.0474]])\n",
      "pts2 after scaling:  tensor([[0.3887, 0.4117],\n",
      "        [0.3887, 0.5883],\n",
      "        [0.5712, 0.6006],\n",
      "        [0.5712, 0.3994]])\n"
     ]
    }
   ],
   "source": [
    "perspective=True\n",
    "scaling=True\n",
    "rotation=True\n",
    "translation=True\n",
    "n_scales=5\n",
    "n_angles=25\n",
    "scaling_amplitude=0.25\n",
    "perspective_amplitude_x=0.2\n",
    "perspective_amplitude_y=0.2 \n",
    "patch_ratio=0.85\n",
    "max_angle=1.57\n",
    "allow_artifacts=False\n",
    "translation_overflow=0.\n",
    "\n",
    "# Corners of the output image\n",
    "pts1 = torch.Tensor([[0., 0.], [0., 1.], [1., 1.], [1., 0.]])\n",
    "# Corners of the input patch\n",
    "margin = (1 - patch_ratio) / 2\n",
    "pts2 = margin + torch.Tensor([[0, 0], [0, patch_ratio],\n",
    "                             [patch_ratio, patch_ratio], [patch_ratio, 0]])\n",
    "\n",
    "# Random perspective and affine perturbations\n",
    "if True:\n",
    "    if not False:\n",
    "        perspective_amplitude_x = min(perspective_amplitude_x, margin)\n",
    "        perspective_amplitude_y = min(perspective_amplitude_y, margin)\n",
    "    \n",
    "    # create truncated normal distribution\n",
    "    perspective_displacement = truncated_normal(-perspective_amplitude_y, perspective_amplitude_y, perspective_amplitude_y/2)[0]\n",
    "    h_displacement_left = truncated_normal(-perspective_amplitude_x, perspective_amplitude_x, perspective_amplitude_x/2)[0]\n",
    "    h_displacement_right = truncated_normal(-perspective_amplitude_x, perspective_amplitude_x, perspective_amplitude_x/2)[0]\n",
    "    pts2 += torch.Tensor([[h_displacement_left, perspective_displacement], [h_displacement_left, -perspective_displacement],\n",
    "                          [h_displacement_right, perspective_displacement], [h_displacement_right, -perspective_displacement]])\n",
    "\n",
    "print('pts2 after perspective...:', pts2)\n",
    "# Random scaling\n",
    "# sample several scales, check collision with borders, randomly pick a valid one\n",
    "if scaling:\n",
    "    scales = torch.ones([1+n_scales])\n",
    "    scales[1:] = torch.from_numpy(truncated_normal(-scaling_amplitude, scaling_amplitude, scaling_amplitude/2, my_mean=1, sz=n_scales))\n",
    "    center = torch.mean(pts2, dim=0, keepdim=True)\n",
    "    scales = scales.unsqueeze(1).unsqueeze(1)\n",
    "    scaled = (pts2-center).unsqueeze(0) * scales + center\n",
    "#     temp = (pts2-center).unsqueeze(0)\n",
    "#     print('center',center.shape)\n",
    "#     print('temp',temp.shape)\n",
    "#     print('scales', scales.shape)\n",
    "#     print('scaled', scaled)\n",
    "    \n",
    "    if allow_artifacts:\n",
    "        valid = torch.arange(1,n_scales+1) # all scales are valid except scale=1\n",
    "    else:\n",
    "        scaled_boolean = ( (scaled >= 0.) & (scaled < 1.) )\n",
    "        valid = ( (logits).sum(dim=(1,2)) == 8 ).nonzero().squeeze(1) # get the index of valid\n",
    "    # get the index\n",
    "    idx = valid[torch.randint(low=0, high=6, size=(1,),dtype=torch.int32)[0]]\n",
    "    pts2 = scaled[idx]\n",
    "#     print('scaled', scaled)\n",
    "#     print('idx', idx)\n",
    "\n",
    "print(\"pts2 after scaling: \", pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(low=0, high=6, size=(1,),dtype=torch.int32)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal(myclip_a, myclip_b, my_std, my_mean=0., sz=1):\n",
    "    \"\"\"\n",
    "    Generate random numbers from a truncated normal distribution\n",
    "    \"\"\"\n",
    "    a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "    return truncnorm.rvs(a, b, my_mean, my_std, size=sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_homography(\n",
    "        shape, perspective=True, scaling=True, rotation=True, translation=True,\n",
    "        n_scales=5, n_angles=25, scaling_amplitude=0.25, perspective_amplitude_x=0.2,\n",
    "        perspective_amplitude_y=0.2, patch_ratio=0.85, max_angle=1.57,\n",
    "        allow_artifacts=False, translation_overflow=0.):\n",
    "    \"\"\"Sample a random valid homography.\n",
    "\n",
    "    Computes the homography transformation between a random patch in the original image\n",
    "    and a warped projection with the same image size.\n",
    "    As in `tf.contrib.image.transform`, it maps the output point (warped patch) to a\n",
    "    transformed input point (original patch).\n",
    "    The original patch, which is initialized with a simple half-size centered crop, is\n",
    "    iteratively projected, scaled, rotated and translated.\n",
    "\n",
    "    Arguments:\n",
    "        shape: A rank-2 `Tensor` specifying the height and width of the original image.\n",
    "        perspective: A boolean that enables the perspective and affine transformations.\n",
    "        scaling: A boolean that enables the random scaling of the patch.\n",
    "        rotation: A boolean that enables the random rotation of the patch.\n",
    "        translation: A boolean that enables the random translation of the patch.\n",
    "        n_scales: The number of tentative scales that are sampled when scaling.\n",
    "        n_angles: The number of tentatives angles that are sampled when rotating.\n",
    "        scaling_amplitude: Controls the amount of scale.\n",
    "        perspective_amplitude_x: Controls the perspective effect in x direction.\n",
    "        perspective_amplitude_y: Controls the perspective effect in y direction.\n",
    "        patch_ratio: Controls the size of the patches used to create the homography.\n",
    "        max_angle: Maximum angle used in rotations.\n",
    "        allow_artifacts: A boolean that enables artifacts when applying the homography.\n",
    "        translation_overflow: Amount of border artifacts caused by translation.\n",
    "\n",
    "    Returns:\n",
    "        A `Tensor` of shape `[1, 8]` corresponding to the flattened homography transform.\n",
    "    \"\"\"\n",
    "\n",
    "    # Corners of the output image\n",
    "    pts1 = torch.Tensor([[0., 0.], [0., 1.], [1., 1.], [1., 0.]])\n",
    "    # Corners of the input patch\n",
    "    margin = (1 - patch_ratio) / 2\n",
    "    pts2 = margin + torch.Tensor([[0, 0], [0, patch_ratio],\n",
    "                                 [patch_ratio, patch_ratio], [patch_ratio, 0]])\n",
    "    \n",
    "    # Random perspective and affine perturbations\n",
    "    if perspective:\n",
    "        if not allow_artifacts:\n",
    "            perspective_amplitude_x = min(perspective_amplitude_x, margin)\n",
    "            perspective_amplitude_y = min(perspective_amplitude_y, margin)\n",
    "\n",
    "        # create truncated normal distribution\n",
    "        perspective_displacement = truncated_normal(-perspective_amplitude_y, perspective_amplitude_y, perspective_amplitude_y/2)\n",
    "        h_displacement_left = truncated_normal(-perspective_amplitude_x, perspective_amplitude_x, perspective_amplitude_x/2)\n",
    "        h_displacement_right = truncated_normal(-perspective_amplitude_x, perspective_amplitude_x, perspective_amplitude_x/2)\n",
    "        pts2 += torch.Tensor([[h_displacement_left, perspective_displacement], [h_displacement_left, -perspective_displacement],\n",
    "                              [h_displacement_right, perspective_displacement], [h_displacement_right, -perspective_displacement]])\n",
    "\n",
    "    # Random scaling\n",
    "    # sample several scales, check collision with borders, randomly pick a valid one\n",
    "    if scaling:\n",
    "        scales = torch.ones([1+n_scales])\n",
    "        scales[1:] = torch.from_numpy(truncated_normal(-scaling_amplitude, scaling_amplitude, scaling_amplitude/2, my_mean=1, sz=n_scales))\n",
    "        center = torch.mean(pts2, dim=0, keepdim=True)\n",
    "        scales = scales.unsqueeze(1).unsqueeze(1)\n",
    "        scaled = (pts2-center).unsqueeze(0) * scales + center\n",
    "    #     temp = (pts2-center).unsqueeze(0)\n",
    "    #     print('center',center.shape)\n",
    "    #     print('temp',temp.shape)\n",
    "    #     print('scales', scales.shape)\n",
    "    #     print('scaled', scaled)\n",
    "\n",
    "        if allow_artifacts:\n",
    "            valid = torch.arange(1,n_scales+1) # all scales are valid except scale=1\n",
    "        else:\n",
    "            scaled_boolean = ( (scaled >= 0.) & (scaled < 1.) )\n",
    "            valid = ( (logits).sum(dim=(1,2)) == 8 ).nonzero().squeeze(1) # get the index of valid\n",
    "        # get the index\n",
    "        idx = valid[torch.randint(low=0, high=6, size=(1,),dtype=torch.int32)[0]]\n",
    "        pts2 = scaled[idx]\n",
    "    #     print('scaled', scaled)\n",
    "    #     print('idx', idx)\n",
    "\n",
    "    # Random translation\n",
    "    if translation:\n",
    "        t_min, t_max = tf.reduce_min(pts2, axis=0), tf.reduce_min(1 - pts2, axis=0)\n",
    "        if allow_artifacts:\n",
    "            t_min += translation_overflow\n",
    "            t_max += translation_overflow\n",
    "        pts2 += tf.expand_dims(tf.stack([tf.random_uniform((), -t_min[0], t_max[0]),\n",
    "                                         tf.random_uniform((), -t_min[1], t_max[1])]),\n",
    "                               axis=0)\n",
    "\n",
    "    # Random rotation\n",
    "    # sample several rotations, check collision with borders, randomly pick a valid one\n",
    "    if rotation:\n",
    "        angles = tf.lin_space(tf.constant(-max_angle), tf.constant(max_angle), n_angles)\n",
    "        angles = tf.concat([angles, [0.]], axis=0)  # in case no rotation is valid\n",
    "        center = tf.reduce_mean(pts2, axis=0, keepdims=True)\n",
    "        rot_mat = tf.reshape(tf.stack([tf.cos(angles), -tf.sin(angles), tf.sin(angles),\n",
    "                                       tf.cos(angles)], axis=1), [-1, 2, 2])\n",
    "        rotated = tf.matmul(\n",
    "                tf.tile(tf.expand_dims(pts2 - center, axis=0), [n_angles+1, 1, 1]),\n",
    "                rot_mat) + center\n",
    "        if allow_artifacts:\n",
    "            valid = tf.range(n_angles)  # all angles are valid, except angle=0\n",
    "        else:\n",
    "            valid = tf.where(tf.reduce_all((rotated >= 0.) & (rotated < 1.),\n",
    "                                           axis=[1, 2]))[:, 0]\n",
    "        idx = valid[tf.random_uniform((), maxval=tf.shape(valid)[0], dtype=tf.int32)]\n",
    "        pts2 = rotated[idx]\n",
    "\n",
    "    # Rescale to actual size\n",
    "    shape = tf.to_float(shape[::-1])  # different convention [y, x]\n",
    "    pts1 *= tf.expand_dims(shape, axis=0)\n",
    "    pts2 *= tf.expand_dims(shape, axis=0)\n",
    "\n",
    "    def ax(p, q): return [p[0], p[1], 1, 0, 0, 0, -p[0] * q[0], -p[1] * q[0]]\n",
    "\n",
    "    def ay(p, q): return [0, 0, 0, p[0], p[1], 1, -p[0] * q[1], -p[1] * q[1]]\n",
    "\n",
    "    a_mat = tf.stack([f(pts1[i], pts2[i]) for i in range(4) for f in (ax, ay)], axis=0)\n",
    "    p_mat = tf.transpose(tf.stack(\n",
    "        [[pts2[i][j] for i in range(4) for j in range(2)]], axis=0))\n",
    "    homography = tf.transpose(tf.matrix_solve_ls(a_mat, p_mat, fast=True))\n",
    "    return homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_homography_tf(\n",
    "        shape, perspective=True, scaling=True, rotation=True, translation=True,\n",
    "        n_scales=5, n_angles=25, scaling_amplitude=0.25, perspective_amplitude_x=0.2,\n",
    "        perspective_amplitude_y=0.2, patch_ratio=0.85, max_angle=1.57,\n",
    "        allow_artifacts=False, translation_overflow=0.):\n",
    "    \"\"\"Sample a random valid homography.\n",
    "\n",
    "    Computes the homography transformation between a random patch in the original image\n",
    "    and a warped projection with the same image size.\n",
    "    As in `tf.contrib.image.transform`, it maps the output point (warped patch) to a\n",
    "    transformed input point (original patch).\n",
    "    The original patch, which is initialized with a simple half-size centered crop, is\n",
    "    iteratively projected, scaled, rotated and translated.\n",
    "\n",
    "    Arguments:\n",
    "        shape: A rank-2 `Tensor` specifying the height and width of the original image.\n",
    "        perspective: A boolean that enables the perspective and affine transformations.\n",
    "        scaling: A boolean that enables the random scaling of the patch.\n",
    "        rotation: A boolean that enables the random rotation of the patch.\n",
    "        translation: A boolean that enables the random translation of the patch.\n",
    "        n_scales: The number of tentative scales that are sampled when scaling.\n",
    "        n_angles: The number of tentatives angles that are sampled when rotating.\n",
    "        scaling_amplitude: Controls the amount of scale.\n",
    "        perspective_amplitude_x: Controls the perspective effect in x direction.\n",
    "        perspective_amplitude_y: Controls the perspective effect in y direction.\n",
    "        patch_ratio: Controls the size of the patches used to create the homography.\n",
    "        max_angle: Maximum angle used in rotations.\n",
    "        allow_artifacts: A boolean that enables artifacts when applying the homography.\n",
    "        translation_overflow: Amount of border artifacts caused by translation.\n",
    "\n",
    "    Returns:\n",
    "        A `Tensor` of shape `[1, 8]` corresponding to the flattened homography transform.\n",
    "    \"\"\"\n",
    "\n",
    "    pts1 = tf.stack([[0., 0.], [0., 1.], [1., 1.], [1., 0.]], axis=0)\n",
    "    # Corners of the input patch\n",
    "    margin = (1 - patch_ratio) / 2\n",
    "    pts2 = margin + tf.constant([[0, 0], [0, patch_ratio], [patch_ratio, patch_ratio], [patch_ratio, 0]], tf.float32)\n",
    "\n",
    "    \n",
    "    # Random perspective and affine perturbations\n",
    "    if perspective:\n",
    "        if not allow_artifacts:\n",
    "            perspective_amplitude_x = min(perspective_amplitude_x, margin)\n",
    "            perspective_amplitude_y = min(perspective_amplitude_y, margin)\n",
    "\n",
    "        perspective_displacement = tf.truncated_normal([1], 0., perspective_amplitude_y/2)\n",
    "        h_displacement_left = tf.truncated_normal([1], 0., perspective_amplitude_x/2)\n",
    "        h_displacement_right = tf.truncated_normal([1], 0., perspective_amplitude_x/2)\n",
    "        pts2 += tf.stack([tf.concat([h_displacement_left, perspective_displacement], 0),\n",
    "                          tf.concat([h_displacement_left, -perspective_displacement], 0),\n",
    "                          tf.concat([h_displacement_right, perspective_displacement], 0),\n",
    "                          tf.concat([h_displacement_right, -perspective_displacement], 0)])\n",
    "\n",
    "    # Random scaling\n",
    "    # sample several scales, check collision with borders, randomly pick a valid one\n",
    "    if scaling:\n",
    "        scales = tf.concat(\n",
    "                [[1.], tf.truncated_normal([n_scales], 1, scaling_amplitude/2)], 0)\n",
    "        center = tf.reduce_mean(pts2, axis=0, keepdims=True)\n",
    "        scaled = tf.expand_dims(pts2 - center, axis=0) * tf.expand_dims(\n",
    "                tf.expand_dims(scales, 1), 1) + center\n",
    "        if allow_artifacts:\n",
    "            valid = tf.range(n_scales)  # all scales are valid except scale=1\n",
    "        else:\n",
    "            valid = tf.where(tf.reduce_all((scaled >= 0.) & (scaled < 1.), [1, 2]))[:, 0]\n",
    "            \n",
    "        idx = valid[tf.random_uniform((), maxval=tf.shape(valid)[0], dtype=tf.int32)]\n",
    "        pts2 = scaled[idx]\n",
    "\n",
    "    # Random translation\n",
    "    if translation:\n",
    "        t_min, t_max = tf.reduce_min(pts2, axis=0), tf.reduce_min(1 - pts2, axis=0)\n",
    "        if allow_artifacts:\n",
    "            t_min += translation_overflow\n",
    "            t_max += translation_overflow\n",
    "        pts2 += tf.expand_dims(tf.stack([tf.random_uniform((), -t_min[0], t_max[0]),\n",
    "                                         tf.random_uniform((), -t_min[1], t_max[1])]),\n",
    "                               axis=0)\n",
    "\n",
    "    # Random rotation\n",
    "    # sample several rotations, check collision with borders, randomly pick a valid one\n",
    "    if rotation:\n",
    "        angles = tf.lin_space(tf.constant(-max_angle), tf.constant(max_angle), n_angles)\n",
    "        angles = tf.concat([angles, [0.]], axis=0)  # in case no rotation is valid\n",
    "        center = tf.reduce_mean(pts2, axis=0, keepdims=True)\n",
    "        rot_mat = tf.reshape(tf.stack([tf.cos(angles), -tf.sin(angles), tf.sin(angles),\n",
    "                                       tf.cos(angles)], axis=1), [-1, 2, 2])\n",
    "        rotated = tf.matmul(\n",
    "                tf.tile(tf.expand_dims(pts2 - center, axis=0), [n_angles+1, 1, 1]),\n",
    "                rot_mat) + center\n",
    "        if allow_artifacts:\n",
    "            valid = tf.range(n_angles)  # all angles are valid, except angle=0\n",
    "        else:\n",
    "            valid = tf.where(tf.reduce_all((rotated >= 0.) & (rotated < 1.),\n",
    "                                           axis=[1, 2]))[:, 0]\n",
    "        idx = valid[tf.random_uniform((), maxval=tf.shape(valid)[0], dtype=tf.int32)]\n",
    "        pts2 = rotated[idx]\n",
    "\n",
    "    # Rescale to actual size\n",
    "    shape = tf.to_float(shape[::-1])  # different convention [y, x]\n",
    "    pts1 *= tf.expand_dims(shape, axis=0)\n",
    "    pts2 *= tf.expand_dims(shape, axis=0)\n",
    "\n",
    "    def ax(p, q): return [p[0], p[1], 1, 0, 0, 0, -p[0] * q[0], -p[1] * q[0]]\n",
    "\n",
    "    def ay(p, q): return [0, 0, 0, p[0], p[1], 1, -p[0] * q[1], -p[1] * q[1]]\n",
    "\n",
    "    a_mat = tf.stack([f(pts1[i], pts2[i]) for i in range(4) for f in (ax, ay)], axis=0)\n",
    "    p_mat = tf.transpose(tf.stack(\n",
    "        [[pts2[i][j] for i in range(4) for j in range(2)]], axis=0))\n",
    "    homography = tf.transpose(tf.matrix_solve_ls(a_mat, p_mat, fast=True))\n",
    "    return homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_homography(H):\n",
    "    \"\"\"\n",
    "    Computes the inverse transformation for a flattened homography transformation.\n",
    "    \"\"\"\n",
    "    matH = flat2mat(H)\n",
    "    invH = torch.cat([torch.inverse(matH[i,:,:]) for i in range(matH.shape[0])]).view(matH.shape[0],3,3)\n",
    "    return mat2flat(invH)\n",
    "\n",
    "def flat2mat(H):\n",
    "    \"\"\"\n",
    "    Converts a flattened homography with shape '[N, 8]' to its\n",
    "    corresponding homography matrix with shape '[N, 3, 3]'.\n",
    "    \"\"\"\n",
    "    return torch.reshape(torch.cat((H, torch.ones(H.shape[0],1)), dim=1), [-1,3,3])\n",
    "\n",
    "def mat2flat(H):\n",
    "    \"\"\"\n",
    "    Converts homography matrix with shape '[N, 3, 3]' to its\n",
    "    flattened homography with shape '[N, 8]'.\n",
    "    \"\"\"\n",
    "    H = torch.reshape(H, [-1, 9])\n",
    "    return (H / H[:, 8:9])[:, :8]\n",
    "\n",
    "# # unit test\n",
    "# H = torch.ones([10,8])*64\n",
    "# matH = flat2mat(H)\n",
    "# flatH = mat2flat(matH)\n",
    "# print(H)\n",
    "# print(flatH)\n",
    "\n",
    "# H = torch.ones([2,8])\n",
    "# temp = torch.Tensor([1, 0, 3, 2, 1, -1, 4, 2, 4])/4\n",
    "# H[0,:] = temp[:8]\n",
    "# H[1,:] = temp[:8]\n",
    "\n",
    "# print(H)\n",
    "# print(invert_homography(H))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
