{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "import os.path\n",
    "import pdb\n",
    "import argparse\n",
    "import sys\n",
    "from shapes_loader import *\n",
    "from base_model import *\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample homographies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warp image given a homography\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape:  torch.Size([2, 300, 400])\n",
      "ML model output shape:  torch.Size([2, 65, 37, 50])\n",
      "ML model output shape:  torch.Size([2, 256, 37, 50])\n"
     ]
    }
   ],
   "source": [
    "# parameter \n",
    "threshold = 0.05\n",
    "\n",
    "# load in model\n",
    "magic_leap_model = SuperPointNet().to(DEVICE)\n",
    "model = torch.load('./Fri Nov  9 15:54:21 2018/e_405_a_10.9042.model').to(DEVICE)\n",
    "magic_leap_model.load_state_dict(torch.load('superpoint_v1.pth'))\n",
    "\n",
    "\n",
    "# load in images\n",
    "img_dir = '../test_coco/'\n",
    "imgsList = os.listdir(img_dir)\n",
    "clr_imgs = [Image.open(img_dir+img).resize((400,300),Image.ANTIALIAS) for img in imgsList]\n",
    "clr_imgs = clr_imgs[0]\n",
    "imgs = torch.tensor(np.asarray([np.array(Image.open(img_dir+img).resize((400,300),Image.ANTIALIAS).convert('1')) for img in imgsList], dtype='float')).to(DEVICE)  \n",
    "imgs = imgs[0:2]\n",
    "\n",
    "print('original image shape: ', imgs.shape)\n",
    "ipt_1, desc_1 = model(imgs.float().unsqueeze(1).to(DEVICE))\n",
    "ipt_2, desc_2 = magic_leap_model(imgs.float().unsqueeze(1).to(DEVICE))\n",
    "\n",
    "#ipt bnum x 65 x hc x wc\n",
    "bnum, dims, hc, wc = ipt_2.shape\n",
    "print('ML model output shape: ', ipt_2.shape)\n",
    "print('ML model output shape: ', desc_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 65, 37, 50])\n",
      "tensor([  2., 300., 400.])\n",
      "tensor([ 52.0192, 286.1192,   1.0000])\n"
     ]
    }
   ],
   "source": [
    "# homography adaptation\n",
    "counts = torch.ones(ipt_2.shape)\n",
    "\n",
    "print(ipt_2.shape)\n",
    "probs = ipt_2.unsqueeze(-1)\n",
    "counts = counts.unsqueeze(-1)\n",
    "images = imgs.unsqueeze(-1)\n",
    "shape = torch.Tensor([images.shape[:-1]]).squeeze(0)\n",
    "print(shape)\n",
    "\n",
    "homography = sample_homography(shape)\n",
    "\n",
    "homo = flat2mat(homography.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "res = torch.matmul(homo, torch.Tensor([0.,300.,1]))\n",
    "res = res/res[2]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_homography(\n",
    "        shape, perspective=True, scaling=True, rotation=True, translation=True,\n",
    "        n_scales=5, n_angles=25, scaling_amplitude=0.25, perspective_amplitude_x=0.2,\n",
    "        perspective_amplitude_y=0.2, patch_ratio=0.85, max_angle=1.57,\n",
    "        allow_artifacts=False, translation_overflow=0.):\n",
    "    \"\"\"Sample a random valid homography.\n",
    "\n",
    "    Computes the homography transformation between a random patch in the original image\n",
    "    and a warped projection with the same image size.\n",
    "    As in `tf.contrib.image.transform`, it maps the output point (warped patch) to a\n",
    "    transformed input point (original patch).\n",
    "    The original patch, which is initialized with a simple half-size centered crop, is\n",
    "    iteratively projected, scaled, rotated and translated.\n",
    "\n",
    "    Arguments:\n",
    "        shape: A rank-2 `Tensor` specifying the height and width of the original image.\n",
    "        perspective: A boolean that enables the perspective and affine transformations.\n",
    "        scaling: A boolean that enables the random scaling of the patch.\n",
    "        rotation: A boolean that enables the random rotation of the patch.\n",
    "        translation: A boolean that enables the random translation of the patch.\n",
    "        n_scales: The number of tentative scales that are sampled when scaling.\n",
    "        n_angles: The number of tentatives angles that are sampled when rotating.\n",
    "        scaling_amplitude: Controls the amount of scale.\n",
    "        perspective_amplitude_x: Controls the perspective effect in x direction.\n",
    "        perspective_amplitude_y: Controls the perspective effect in y direction.\n",
    "        patch_ratio: Controls the size of the patches used to create the homography.\n",
    "        max_angle: Maximum angle used in rotations.\n",
    "        allow_artifacts: A boolean that enables artifacts when applying the homography.\n",
    "        translation_overflow: Amount of border artifacts caused by translation.\n",
    "\n",
    "    Returns:\n",
    "        A `Tensor` of shape `[1, 8]` corresponding to the flattened homography transform.\n",
    "    \"\"\"\n",
    "\n",
    "    # Corners of the output image\n",
    "    pts1 = torch.Tensor([[0., 0.], [0., 1.], [1., 1.], [1., 0.]])\n",
    "    # Corners of the input patch\n",
    "    margin = (1 - patch_ratio) / 2\n",
    "    pts2 = margin + torch.Tensor([[0, 0], [0, patch_ratio],\n",
    "                                 [patch_ratio, patch_ratio], [patch_ratio, 0]])\n",
    "#     print('pts2 initially...:', pts2)\n",
    "    \n",
    "    # Random perspective and affine perturbations\n",
    "    if perspective:\n",
    "        if not allow_artifacts:\n",
    "            perspective_amplitude_x = min(perspective_amplitude_x, margin)\n",
    "            perspective_amplitude_y = min(perspective_amplitude_y, margin)\n",
    "\n",
    "        # create truncated normal distribution\n",
    "        perspective_displacement = truncated_normal(-perspective_amplitude_y, perspective_amplitude_y, perspective_amplitude_y/2)[0]\n",
    "        h_displacement_left = truncated_normal(-perspective_amplitude_x, perspective_amplitude_x, perspective_amplitude_x/2)[0]\n",
    "        h_displacement_right = truncated_normal(-perspective_amplitude_x, perspective_amplitude_x, perspective_amplitude_x/2)[0]\n",
    "        pts2 += torch.Tensor([[h_displacement_left, perspective_displacement], [h_displacement_left, -perspective_displacement],\n",
    "                              [h_displacement_right, perspective_displacement], [h_displacement_right, -perspective_displacement]])\n",
    "#     print('pts2 after perspective...:', pts2)\n",
    "    \n",
    "    # Random scaling\n",
    "    # sample several scales, check collision with borders, randomly pick a valid one\n",
    "    if scaling:\n",
    "        scales = torch.ones([1+n_scales])\n",
    "        scales[:-1] = torch.from_numpy(truncated_normal(-scaling_amplitude, scaling_amplitude, scaling_amplitude/2, my_mean=1, sz=n_scales))\n",
    "        center = torch.mean(pts2, dim=0, keepdim=True)\n",
    "        scales = scales.unsqueeze(1).unsqueeze(1)\n",
    "        scaled = (pts2-center).unsqueeze(0) * scales + center\n",
    "    #     temp = (pts2-center).unsqueeze(0)\n",
    "    #     print('center',center.shape)\n",
    "    #     print('temp',temp.shape)\n",
    "    #     print('scales', scales.shape)\n",
    "    #     print('scaled', scaled)\n",
    "\n",
    "        if allow_artifacts:\n",
    "            valid = torch.arange(n_scales) # all scales are valid except scale=1\n",
    "        else:\n",
    "            scaled_boolean = ( (scaled >= 0.) & (scaled < 1.) )\n",
    "            valid = ( (scaled_boolean).sum(dim=(1,2)) == 8 ).nonzero().squeeze(1) # get the index of valid\n",
    "        # get the index\n",
    "        idx = valid[torch.randint(low=0, high=6, size=(1,),dtype=torch.int32)[0]]\n",
    "        pts2 = scaled[idx]\n",
    "        \n",
    "#     print('scale is:', scales[idx], 'center is:', center)\n",
    "#     print(\"pts2 after scaling: \", pts2)\n",
    "\n",
    "    # Random translation\n",
    "    if translation:\n",
    "        t_min, t_max = torch.min(pts2, dim=0), torch.min(1-pts2, dim=0)\n",
    "        t_min = t_min[0]\n",
    "        t_max = t_max[0]\n",
    "\n",
    "        if allow_artifacts:\n",
    "            t_min += translation_overflow\n",
    "            t_max += translation_overflow\n",
    "\n",
    "#         print(torch.randn(1) * (t_max[0]+t_min[0]) - t_min[0])\n",
    "#         print('t min',t_min)\n",
    "#         print('t max',t_max)\n",
    "#         print( torch.rand(1) * (t_max[1]+t_min[1]) - t_min[1] )\n",
    "        temp = torch.Tensor([[torch.rand(1) * (t_max[0]+t_min[0]) - t_min[0],\n",
    "                              torch.rand(1) * (t_max[1]+t_min[1]) - t_min[1]]])\n",
    "        pts2 += temp\n",
    "#     print(\"pts2 after translation: \",pts2)\n",
    "#     print(\"The translation is: \", temp)\n",
    "\n",
    "    # Random rotation\n",
    "    # sample several rotations, check collision with borders, randomly pick a valid one\n",
    "    if rotation:\n",
    "        # sample angles\n",
    "        angles = torch.linspace(-max_angle, max_angle, n_angles)\n",
    "        angles = torch.cat((angles, torch.zeros(1)))\n",
    "        # get rotation matrix\n",
    "        rot_mat = torch.t(torch.cat([torch.from_numpy(np.cos(angles.numpy())), \n",
    "                                     torch.from_numpy(-np.sin(angles.numpy())),\n",
    "                                     torch.from_numpy(np.sin(angles.numpy())),\n",
    "                                     torch.from_numpy(np.cos(angles.numpy()))]).view(4,-1)).view(-1,2,2)\n",
    "        # get center of rotation\n",
    "        center = torch.mean(pts2, dim=0, keepdim=True)\n",
    "        # apply rotation\n",
    "        rotated = torch.matmul((pts2-center).unsqueeze(0).repeat(n_angles+1,1,1), rot_mat) + center\n",
    "\n",
    "        if allow_artifacts:\n",
    "            valid = torch.arange(n_angles)  # all angles are valid, except angle=0\n",
    "        else:\n",
    "            rotated_boolean = ( (rotated >= 0.) & (rotated < 1.) )\n",
    "            valid = ( rotated_boolean.sum(dim=(1,2)) == 8 ).nonzero()#.squeeze(1) # get the index of valid\n",
    "        # get the index\n",
    "        idx = valid[torch.randint(low=0, high=valid.shape[0], size=(1,), dtype=torch.int32)[0]]\n",
    "        pts2 = rotated[idx].squeeze(0)\n",
    "#     print('pts2 after rotation:',pts2)\n",
    "#     print('The rotation angle is:',angles[idx])\n",
    "#     print('The rotation matrix is:',rot_mat[idx])\n",
    "\n",
    "    # Rescale to actual size\n",
    "    pts1 = pts1 * torch.from_numpy(np.flip(shape.numpy(),0).copy())[:-1] # different convention [y, x]\n",
    "    pts2 = pts2 * torch.from_numpy(np.flip(shape.numpy(),0).copy())[:-1] # different convention [y, x]\n",
    "#     print('unsq pts1', pts1)\n",
    "#     print('unsq pts2', pts2)\n",
    "\n",
    "    # LS to estimate a H from 4 point pairs: AH = p\n",
    "    def ax(p, q): return [p[0], p[1], 1, 0, 0, 0, -p[0] * q[0], -p[1] * q[0]]\n",
    "    def ay(p, q): return [0, 0, 0, p[0], p[1], 1, -p[0] * q[1], -p[1] * q[1]]\n",
    "\n",
    "    a_mat = torch.FloatTensor([f(pts1[i], pts2[i]) for i in range(4) for f in (ax, ay)])\n",
    "#     print('A',a_mat)\n",
    "    p_mat = torch.t(torch.FloatTensor([[pts2[i][j] for i in range(4) for j in range(2)]]))\n",
    "#     print('P',p_mat)\n",
    "    homography = torch.t(torch.from_numpy(np.linalg.lstsq(a_mat, p_mat)[0])).squeeze(0)\n",
    "    return homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal(myclip_a, myclip_b, my_std, my_mean=0., sz=1):\n",
    "    \"\"\"\n",
    "    Generate random numbers from a truncated normal distribution\n",
    "    \"\"\"\n",
    "    a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "    return truncnorm.rvs(a, b, my_mean, my_std, size=sz)\n",
    "\n",
    "def invert_homography(H):\n",
    "    \"\"\"\n",
    "    Computes the inverse transformation for a flattened homography transformation.\n",
    "    \"\"\"\n",
    "    matH = flat2mat(H)\n",
    "    invH = torch.cat([torch.inverse(matH[i,:,:]) for i in range(matH.shape[0])]).view(matH.shape[0],3,3)\n",
    "    return mat2flat(invH)\n",
    "\n",
    "def flat2mat(H):\n",
    "    \"\"\"\n",
    "    Converts a flattened homography with shape '[N, 8]' to its\n",
    "    corresponding homography matrix with shape '[N, 3, 3]'.\n",
    "    \"\"\"\n",
    "    return torch.reshape(torch.cat((H, torch.ones(H.shape[0],1)), dim=1), [-1,3,3])\n",
    "\n",
    "def mat2flat(H):\n",
    "    \"\"\"\n",
    "    Converts homography matrix with shape '[N, 3, 3]' to its\n",
    "    flattened homography with shape '[N, 8]'.\n",
    "    \"\"\"\n",
    "    H = torch.reshape(H, [-1, 9])\n",
    "    return (H / H[:, 8:9])[:, :8]\n",
    "\n",
    "# # unit test\n",
    "# H = torch.ones([10,8])*64\n",
    "# matH = flat2mat(H)\n",
    "# flatH = mat2flat(matH)\n",
    "# print(H)\n",
    "# print(flatH)\n",
    "\n",
    "# H = torch.ones([2,8])\n",
    "# temp = torch.Tensor([1, 0, 3, 2, 1, -1, 4, 2, 4])/4\n",
    "# H[0,:] = temp[:8]\n",
    "# H[1,:] = temp[:8]\n",
    "\n",
    "# print(H)\n",
    "# print(invert_homography(H))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
